package net.cohesyslab.dc.imitators

import java.util.SplittableRandom

import io.github.carrknight.Observation
import io.github.carrknight.imitators.ExploreAtRandom
import io.github.carrknight.imitators.ExploreExploitImitate
import io.github.carrknight.utils.RewardFunction
import io.github.carrknight.utils.rules.ObservationPredicate
import net.cohesyslab.dc.ChooserObject
import net.cohesyslab.dc.IdentityRewardFunction
import net.cohesyslab.dc.NumberGetter
import net.cohesyslab.dc.NumberSetter
import net.cohesyslab.dc.RichArgument
import org.nlogo.api.Argument
import org.nlogo.api.Context
import org.nlogo.api.ExtensionException
import org.nlogo.api.Reporter
import org.nlogo.core.Syntax
import org.nlogo.core.Syntax.AgentsetType
import org.nlogo.core.Syntax.ListType
import org.nlogo.core.Syntax.WildcardType
import org.nlogo.core.Syntax.reporterSyntax

object ExploreExploitImitateChooserPrim extends Reporter {

  val DefaultExplorationProbability = 0.2
  val DefaultImitationProbability = 0.2

  override def getSyntax: Syntax = reporterSyntax(
    right = List(ListType | AgentsetType), // the choices
    ret = WildcardType
  )
  override def report(args: Array[Argument], context: Context): AnyRef =
    new ChooserObject(
      new ExploreExploitImitate[AnyRef, Double, Null](
        IdentityRewardFunction,
        args(0).getOptionsArray(context.getRNG),
        new StochasticObservationPredicate[AnyRef, Double, Null](DefaultExplorationProbability),
        new StochasticObservationPredicate[AnyRef, Double, Null](DefaultImitationProbability),
        new SplittableRandom(context.getRNG.nextLong()), // random seed
        new ExploreAtRandom[AnyRef, Double, Null]
      )
    )
}

/**
 * Same as {@link io.github.carrknight.utils.rules.StochasticObservationPredicate}
 * but keeps track of the exploration probability.
 */
class StochasticObservationPredicate[O, R, C](val explorationProbability: Double) extends ObservationPredicate[O, R, C] {
  override def shouldExplore(
    lastObservation: Observation[O, R, C],
    currentChoice: O,
    rewardFunction: RewardFunction[O, R, C],
    random: SplittableRandom,
    additionalObservations: Observation[O, R, C]*
  ): Boolean = random.nextDouble < explorationProbability
}

object ExplorationProbabilityPrim extends NumberGetter[ExploreExploitImitate[_, _, _]](
  _.getExplorationRule match {
    case rule: StochasticObservationPredicate[_, _, _] => rule.explorationProbability
    case _ => throw new ExtensionException("Exploration rule is not stochastic.")
  }
)

object SetExplorationProbabilityPrim extends NumberSetter[ExploreExploitImitate[_, _, _]](
  (chooser, p) => chooser.setExplorationRule(new StochasticObservationPredicate[_, _, _](p))
)

object ImitationProbabilityPrim extends NumberGetter[ExploreExploitImitate[_, _, _]](
  _.getImitationRule match {
    case rule: StochasticObservationPredicate[_, _, _] => rule.explorationProbability
    case _ => throw new ExtensionException("Imitation rule is not stochastic.")
  }
)

object SetImitationProbabilityPrim extends NumberSetter[ExploreExploitImitate[_, _, _]](
  (chooser, p) => chooser.setExplorationRule(new StochasticObservationPredicate[_, _, _](p))
)